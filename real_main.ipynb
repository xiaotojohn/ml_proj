{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import ast\n",
    "from scipy.stats import uniform, randint\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_pd = pd.read_csv('wine_pd.csv')\n",
    "wine_pd = wine_pd[['tokens','points']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(wine_pd, random_state=42)\n",
    "\n",
    "X_train = train['tokens']\n",
    "y_train = train['points']\n",
    "X_test = test['tokens']\n",
    "y_test = test['points']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "118969    aromatically dazzling wine shows complex notes...\n",
       "3136      earthy deep true uco valley roots good fairly ...\n",
       "77944     made moscato giallo grapes harvested late thou...\n",
       "64964     fresh informal lean easygoing red offers aroma...\n",
       "5082      snappy dry redfruit citrus aromas good opening...\n",
       "Name: tokens, dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train.apply(lambda x: ast.literal_eval(x))\n",
    "\n",
    "# Join the lists into single strings\n",
    "X_train = X_train.apply(lambda tokens: ' '.join(tokens))\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "118969    94\n",
       "3136      89\n",
       "77944     90\n",
       "64964     85\n",
       "5082      87\n",
       "Name: points, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "118969    90\n",
       "3136      85\n",
       "77944     85\n",
       "64964     80\n",
       "5082      85\n",
       "Name: points, dtype: category\n",
       "Categories (4, int64): [80 < 85 < 90 < 95]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the intervals\n",
    "intervals = [80, 85, 90, 95, 100]\n",
    "\n",
    "# Split the numbers into intervals\n",
    "y_train_intervals = pd.cut(y_train, bins=intervals, labels=intervals[:-1], include_lowest=True)\n",
    "y_test_intervals = pd.cut(y_test, bins=intervals, labels=intervals[:-1], include_lowest=True)\n",
    "# Print the result\n",
    "\n",
    "\n",
    "\n",
    "y_train_intervals.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77718    possibly little sweet soft easygoing chardonna...\n",
       "67681    soft almost dry wine full mouth caramel spice ...\n",
       "69877    generic whitefruit aromas peach apple slightly...\n",
       "46544    winerys best nebula years still little soft sw...\n",
       "186      rich pinot whose primary virtue fruit explodes...\n",
       "Name: tokens, dtype: object"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = X_test.apply(lambda x: ast.literal_eval(x))\n",
    "\n",
    "# Join the lists into single strings\n",
    "X_test = X_test.apply(lambda tokens: ' '.join(tokens))\n",
    "\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 23.64%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Assuming wine_train_X, wine_train_y, wine_test_X, wine_test_y are already loaded\n",
    "\n",
    "# Step 1: Create a pipeline with CountVectorizer and MultinomialNB\n",
    "model = make_pipeline(CountVectorizer(), MultinomialNB())\n",
    "\n",
    "# Step 2: Train the model with the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Step 3: Predict labels for the test data\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Optional: Evaluate the model\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV 1/5] END clf__alpha=0.7, vect__max_df=0.5, vect__max_features=15390;, score=(train=0.722, test=0.693) total time=   1.5s\n",
      "[CV 2/5] END clf__alpha=0.7, vect__max_df=0.5, vect__max_features=15390;, score=(train=0.723, test=0.689) total time=   1.5s\n",
      "[CV 4/5] END clf__alpha=0.7, vect__max_df=0.5, vect__max_features=15390;, score=(train=0.723, test=0.690) total time=   1.5s\n",
      "[CV 5/5] END clf__alpha=0.7, vect__max_df=0.5, vect__max_features=15390;, score=(train=0.723, test=0.691) total time=   1.5s\n",
      "[CV 1/5] END clf__alpha=1.0999999999999999, vect__max_df=0.5, vect__max_features=21284;, score=(train=0.699, test=0.672) total time=   1.5s\n",
      "[CV 3/5] END clf__alpha=0.7, vect__max_df=0.5, vect__max_features=15390;, score=(train=0.722, test=0.689) total time=   1.6s\n",
      "[CV 2/5] END clf__alpha=1.0999999999999999, vect__max_df=0.5, vect__max_features=21284;, score=(train=0.699, test=0.671) total time=   1.6s\n",
      "[CV 3/5] END clf__alpha=1.0999999999999999, vect__max_df=0.5, vect__max_features=21284;, score=(train=0.699, test=0.668) total time=   1.6s\n",
      "[CV 4/5] END clf__alpha=1.0999999999999999, vect__max_df=0.5, vect__max_features=21284;, score=(train=0.701, test=0.671) total time=   1.6s\n",
      "[CV 5/5] END clf__alpha=1.0999999999999999, vect__max_df=0.5, vect__max_features=21284;, score=(train=0.700, test=0.668) total time=   1.5s\n",
      "[CV 1/5] END clf__alpha=0.7, vect__max_df=0.75, vect__max_features=26850;, score=(train=0.716, test=0.680) total time=   1.3s\n",
      "[CV 2/5] END clf__alpha=0.7, vect__max_df=0.75, vect__max_features=26850;, score=(train=0.717, test=0.679) total time=   1.2s\n",
      "[CV 3/5] END clf__alpha=0.7, vect__max_df=0.75, vect__max_features=26850;, score=(train=0.716, test=0.677) total time=   1.3s\n",
      "[CV 4/5] END clf__alpha=0.7, vect__max_df=0.75, vect__max_features=26850;, score=(train=0.717, test=0.678) total time=   1.3s\n",
      "[CV 5/5] END clf__alpha=0.7, vect__max_df=0.75, vect__max_features=26850;, score=(train=0.717, test=0.675) total time=   1.3s\n",
      "[CV 1/5] END clf__alpha=1.0999999999999999, vect__max_df=1.0, vect__max_features=24423;, score=(train=0.692, test=0.665) total time=   1.4s\n",
      "[CV 2/5] END clf__alpha=1.0999999999999999, vect__max_df=1.0, vect__max_features=24423;, score=(train=0.694, test=0.664) total time=   1.3s\n",
      "[CV 3/5] END clf__alpha=1.0999999999999999, vect__max_df=1.0, vect__max_features=24423;, score=(train=0.693, test=0.662) total time=   1.4s\n",
      "[CV 5/5] END clf__alpha=1.0999999999999999, vect__max_df=1.0, vect__max_features=24423;, score=(train=0.694, test=0.661) total time=   1.3s\n",
      "[CV 4/5] END clf__alpha=1.0999999999999999, vect__max_df=1.0, vect__max_features=24423;, score=(train=0.694, test=0.663) total time=   1.4s\n",
      "[CV 1/5] END clf__alpha=0.4, vect__max_df=1.0, vect__max_features=11685;, score=(train=0.729, test=0.699) total time=   1.6s\n",
      "[CV 3/5] END clf__alpha=0.4, vect__max_df=1.0, vect__max_features=11685;, score=(train=0.729, test=0.696) total time=   1.6s\n",
      "[CV 2/5] END clf__alpha=0.4, vect__max_df=1.0, vect__max_features=11685;, score=(train=0.729, test=0.694) total time=   1.7s\n",
      "[CV 4/5] END clf__alpha=0.4, vect__max_df=1.0, vect__max_features=11685;, score=(train=0.730, test=0.698) total time=   1.6s\n",
      "[CV 5/5] END clf__alpha=0.4, vect__max_df=1.0, vect__max_features=11685;, score=(train=0.730, test=0.697) total time=   1.7s\n",
      "[CV 2/5] END clf__alpha=0.2, vect__max_df=0.75, vect__max_features=12433;, score=(train=0.737, test=0.695) total time=   1.5s\n",
      "[CV 1/5] END clf__alpha=0.2, vect__max_df=0.75, vect__max_features=12433;, score=(train=0.737, test=0.700) total time=   1.5s\n",
      "[CV 3/5] END clf__alpha=0.2, vect__max_df=0.75, vect__max_features=12433;, score=(train=0.736, test=0.698) total time=   1.6s\n",
      "[CV 4/5] END clf__alpha=0.2, vect__max_df=0.75, vect__max_features=12433;, score=(train=0.737, test=0.699) total time=   1.5s\n",
      "[CV 5/5] END clf__alpha=0.2, vect__max_df=0.75, vect__max_features=12433;, score=(train=0.737, test=0.699) total time=   1.6s\n",
      "[CV 1/5] END clf__alpha=0.1, vect__max_df=0.75, vect__max_features=16396;, score=(train=0.752, test=0.700) total time=   1.5s\n",
      "[CV 3/5] END clf__alpha=0.1, vect__max_df=0.75, vect__max_features=16396;, score=(train=0.752, test=0.699) total time=   1.5s\n",
      "[CV 2/5] END clf__alpha=1.2, vect__max_df=0.5, vect__max_features=18666;, score=(train=0.699, test=0.673) total time=   1.4s\n",
      "[CV 2/5] END clf__alpha=0.1, vect__max_df=0.75, vect__max_features=16396;, score=(train=0.752, test=0.696) total time=   1.6s\n",
      "[CV 4/5] END clf__alpha=0.1, vect__max_df=0.75, vect__max_features=16396;, score=(train=0.751, test=0.698) total time=   1.7s\n",
      "[CV 1/5] END clf__alpha=1.2, vect__max_df=0.5, vect__max_features=18666;, score=(train=0.699, test=0.674) total time=   1.5s\n",
      "[CV 3/5] END clf__alpha=1.2, vect__max_df=0.5, vect__max_features=18666;, score=(train=0.698, test=0.670) total time=   1.5s\n",
      "[CV 4/5] END clf__alpha=1.2, vect__max_df=0.5, vect__max_features=18666;, score=(train=0.700, test=0.672) total time=   1.4s\n",
      "[CV 5/5] END clf__alpha=0.1, vect__max_df=0.75, vect__max_features=16396;, score=(train=0.752, test=0.699) total time=   1.7s\n",
      "[CV 5/5] END clf__alpha=1.2, vect__max_df=0.5, vect__max_features=18666;, score=(train=0.700, test=0.669) total time=   1.4s\n",
      "[CV 1/5] END clf__alpha=0.9999999999999999, vect__max_df=1.0, vect__max_features=10189;, score=(train=0.714, test=0.691) total time=   1.3s\n",
      "[CV 2/5] END clf__alpha=0.9999999999999999, vect__max_df=1.0, vect__max_features=10189;, score=(train=0.714, test=0.690) total time=   1.3s\n",
      "[CV 4/5] END clf__alpha=0.9999999999999999, vect__max_df=1.0, vect__max_features=10189;, score=(train=0.715, test=0.690) total time=   1.3s\n",
      "[CV 3/5] END clf__alpha=0.9999999999999999, vect__max_df=1.0, vect__max_features=10189;, score=(train=0.714, test=0.689) total time=   1.3s\n",
      "[CV 1/5] END clf__alpha=1.5, vect__max_df=0.75, vect__max_features=11899;, score=(train=0.700, test=0.682) total time=   1.5s\n",
      "[CV 5/5] END clf__alpha=0.9999999999999999, vect__max_df=1.0, vect__max_features=10189;, score=(train=0.714, test=0.692) total time=   1.4s\n",
      "[CV 2/5] END clf__alpha=1.5, vect__max_df=0.75, vect__max_features=11899;, score=(train=0.701, test=0.680) total time=   1.4s\n",
      "[CV 3/5] END clf__alpha=1.5, vect__max_df=0.75, vect__max_features=11899;, score=(train=0.701, test=0.678) total time=   1.5s\n",
      "[CV 4/5] END clf__alpha=1.5, vect__max_df=0.75, vect__max_features=11899;, score=(train=0.702, test=0.679) total time=   1.4s\n",
      "[CV 5/5] END clf__alpha=1.5, vect__max_df=0.75, vect__max_features=11899;, score=(train=0.701, test=0.679) total time=   1.4s\n",
      "Best parameters set:\n",
      "{'clf__alpha': 0.1, 'vect__max_df': 0.75, 'vect__max_features': 16396}\n"
     ]
    }
   ],
   "source": [
    "nb_pipeline = Pipeline([\n",
    "    ('vect', TfidfVectorizer()),\n",
    "    ('clf', MultinomialNB())\n",
    "])\n",
    "\n",
    "# Define the parameter space for the random search\n",
    "nb_parameters = {\n",
    "    'vect__ngram_range': ((1, 1), (1, 2)),  # unigrams or bigrams\n",
    "    'vect__max_features': randint(10000,30000),  # number of features to consider\n",
    "    'vect__max_df': (0.5, 0.75, 1.0),\n",
    "    'clf__alpha': np.linspace(0.1, 2, 20),  # smoothing parameter\n",
    "}\n",
    "\n",
    "# Set up the random search with cross-validation\n",
    "nb_random_search = RandomizedSearchCV(nb_pipeline, nb_parameters, n_iter=10, cv=5, random_state=42,verbose=3,return_train_score=True, n_jobs=-1)\n",
    "\n",
    "# Execute the random search\n",
    "nb_random_search.fit(X_train, y_train_intervals)\n",
    "\n",
    "# Output the best parameters\n",
    "print(\"Best parameters set:\")\n",
    "print(nb_random_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Search Score: 69.44%\n"
     ]
    }
   ],
   "source": [
    "score = nb_random_search.score(X_test, y_test_intervals)\n",
    "print(f\"Random Search Score: {score * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "[CV 1/3] END svc__C=0.6808361216819946, svc__gamma=0.9661761457749352;, score=(train=0.595, test=0.574) total time=108.0min\n",
      "[CV 1/3] END svc__C=1.6601864044243653, svc__gamma=0.2559945203362026;, score=(train=1.000, test=0.614) total time=330.6min\n",
      "[CV 2/3] END svc__C=1.6601864044243653, svc__gamma=0.2559945203362026;, score=(train=1.000, test=0.617) total time=417.1min\n",
      "[CV 3/3] END svc__C=1.6601864044243653, svc__gamma=0.2559945203362026;, score=(train=1.000, test=0.616) total time=433.2min\n",
      "[CV 1/3] END svc__C=7.41993941811405, svc__gamma=0.6986584841970366;, score=(train=1.000, test=0.593) total time=831.3min\n",
      "[CV 1/3] END svc__C=3.845401188473625, svc__gamma=1.0507143064099163;, score=(train=1.000, test=0.593) total time=832.9min\n",
      "[CV 2/3] END svc__C=3.845401188473625, svc__gamma=1.0507143064099163;, score=(train=1.000, test=0.594) total time=833.6min\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[95], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m random_search \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(model, param_distributions, n_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, return_train_score\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Step 3: Train the model with the training data\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m \u001b[43mrandom_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_intervals\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/509/lib/python3.10/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/509/lib/python3.10/site-packages/sklearn/model_selection/_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    892\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    894\u001b[0m     )\n\u001b[1;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 898\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    902\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/509/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1809\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1807\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1808\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1809\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1810\u001b[0m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1811\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\n\u001b[1;32m   1812\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1813\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/509/lib/python3.10/site-packages/sklearn/model_selection/_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    838\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    839\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    842\u001b[0m         )\n\u001b[1;32m    843\u001b[0m     )\n\u001b[0;32m--> 845\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    849\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    850\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    851\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    865\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    866\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    867\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/509/lib/python3.10/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/509/lib/python3.10/site-packages/joblib/parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1946\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   1947\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   1948\u001b[0m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[1;32m   1949\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   1950\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1952\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/509/lib/python3.10/site-packages/joblib/parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1592\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1594\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1595\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1597\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1598\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1599\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1600\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1601\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/509/lib/python3.10/site-packages/joblib/parallel.py:1707\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1702\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1703\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1704\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1705\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1706\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1707\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1708\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1710\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1711\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1712\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Step 1: Create a pipeline with CountVectorizer and SVM\n",
    "model = make_pipeline(CountVectorizer(), SVC())\n",
    "\n",
    "# Step 2: Random Search\n",
    "param_distributions = {\n",
    "    'svc__C': uniform(0.1, 10),\n",
    "    'svc__gamma': uniform(0.1, 1)\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(model, param_distributions, n_iter=5, cv=3, random_state=42, verbose=3, return_train_score=True, n_jobs=-1)\n",
    "\n",
    "# Step 3: Train the model with the training data\n",
    "random_search.fit(X_train, y_train_intervals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77718    possibly little sweet soft easygoing chardonna...\n",
       "67681    soft almost dry wine full mouth caramel spice ...\n",
       "69877    generic whitefruit aromas peach apple slightly...\n",
       "46544    winerys best nebula years still little soft sw...\n",
       "186      rich pinot whose primary virtue fruit explodes...\n",
       "Name: tokens, dtype: object"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "[CV 1/3] END countvectorizer__max_df=1.0, countvectorizer__max_features=8860, countvectorizer__ngram_range=(1, 1), kneighborsregressor__n_neighbors=7, kneighborsregressor__weights=distance;, score=(train=1.000, test=-1.025) total time=  56.9s\n",
      "[CV 2/3] END countvectorizer__max_df=1.0, countvectorizer__max_features=8860, countvectorizer__ngram_range=(1, 1), kneighborsregressor__n_neighbors=7, kneighborsregressor__weights=distance;, score=(train=1.000, test=-0.722) total time=  55.1s\n",
      "[CV 3/3] END countvectorizer__max_df=1.0, countvectorizer__max_features=8860, countvectorizer__ngram_range=(1, 1), kneighborsregressor__n_neighbors=7, kneighborsregressor__weights=distance;, score=(train=1.000, test=-0.658) total time=  51.6s\n",
      "[CV 1/3] END countvectorizer__max_df=0.5, countvectorizer__max_features=11092, countvectorizer__ngram_range=(1, 1), kneighborsregressor__n_neighbors=5, kneighborsregressor__weights=uniform;, score=(train=-0.447, test=-1.251) total time=  55.2s\n",
      "[CV 2/3] END countvectorizer__max_df=0.5, countvectorizer__max_features=11092, countvectorizer__ngram_range=(1, 1), kneighborsregressor__n_neighbors=5, kneighborsregressor__weights=uniform;, score=(train=-0.087, test=-0.717) total time=  55.7s\n",
      "[CV 3/3] END countvectorizer__max_df=0.5, countvectorizer__max_features=11092, countvectorizer__ngram_range=(1, 1), kneighborsregressor__n_neighbors=5, kneighborsregressor__weights=uniform;, score=(train=-0.032, test=-0.629) total time=  54.1s\n",
      "[CV 1/3] END countvectorizer__max_df=1.0, countvectorizer__max_features=12426, countvectorizer__ngram_range=(1, 1), kneighborsregressor__n_neighbors=15, kneighborsregressor__weights=distance;, score=(train=1.000, test=-1.121) total time=  57.4s\n",
      "[CV 2/3] END countvectorizer__max_df=1.0, countvectorizer__max_features=12426, countvectorizer__ngram_range=(1, 1), kneighborsregressor__n_neighbors=15, kneighborsregressor__weights=distance;, score=(train=1.000, test=-0.850) total time=  58.2s\n",
      "[CV 3/3] END countvectorizer__max_df=1.0, countvectorizer__max_features=12426, countvectorizer__ngram_range=(1, 1), kneighborsregressor__n_neighbors=15, kneighborsregressor__weights=distance;, score=(train=1.000, test=-0.725) total time= 9.0min\n",
      "[CV 1/3] END countvectorizer__max_df=1.0, countvectorizer__max_features=9685, countvectorizer__ngram_range=(1, 1), kneighborsregressor__n_neighbors=5, kneighborsregressor__weights=distance;, score=(train=1.000, test=-1.017) total time=26.7min\n",
      "[CV 2/3] END countvectorizer__max_df=1.0, countvectorizer__max_features=9685, countvectorizer__ngram_range=(1, 1), kneighborsregressor__n_neighbors=5, kneighborsregressor__weights=distance;, score=(train=1.000, test=-0.647) total time=  56.8s\n",
      "[CV 3/3] END countvectorizer__max_df=1.0, countvectorizer__max_features=9685, countvectorizer__ngram_range=(1, 1), kneighborsregressor__n_neighbors=5, kneighborsregressor__weights=distance;, score=(train=1.000, test=-0.604) total time=  56.9s\n",
      "[CV 1/3] END countvectorizer__max_df=0.75, countvectorizer__max_features=14949, countvectorizer__ngram_range=(1, 2), kneighborsregressor__n_neighbors=10, kneighborsregressor__weights=uniform;, score=(train=-1.170, test=-1.707) total time=  56.9s\n",
      "[CV 2/3] END countvectorizer__max_df=0.75, countvectorizer__max_features=14949, countvectorizer__ngram_range=(1, 2), kneighborsregressor__n_neighbors=10, kneighborsregressor__weights=uniform;, score=(train=-0.561, test=-1.007) total time=  56.1s\n",
      "[CV 3/3] END countvectorizer__max_df=0.75, countvectorizer__max_features=14949, countvectorizer__ngram_range=(1, 2), kneighborsregressor__n_neighbors=10, kneighborsregressor__weights=uniform;, score=(train=-0.416, test=-0.807) total time=  57.8s\n",
      "Best parameters set:\n",
      "{'countvectorizer__max_df': 1.0, 'countvectorizer__max_features': 9685, 'countvectorizer__ngram_range': (1, 1), 'kneighborsregressor__n_neighbors': 5, 'kneighborsregressor__weights': 'distance'}\n",
      "-0.7558828429283105\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "KNN_regression_model = make_pipeline(CountVectorizer(), KNeighborsRegressor())\n",
    "KNN_regression_model.fit(X_train, y_train_intervals)\n",
    "\n",
    "# Step 2: Define the parameter space for the random search\n",
    "\n",
    "parameters = {\n",
    "    'countvectorizer__max_features': randint(8000,15000),  # number of words in the vocabulary\n",
    "    'countvectorizer__max_df': (0.5, 0.75, 1.0),\n",
    "    'kneighborsregressor__n_neighbors': [3, 5, 7, 10, 15],\n",
    "    'kneighborsregressor__weights': ['uniform', 'distance'],\n",
    "}\n",
    "\n",
    "# Step 3: Set up the random search with cross-validation\n",
    "KNN_random_search = RandomizedSearchCV(KNN_regression_model, parameters, n_iter=5, cv=3,verbose=3, random_state=42,return_train_score=True)\n",
    "\n",
    "KNN_random_search.fit(X_train, y_train_intervals)\n",
    "\n",
    "# Output the best parameters\n",
    "print(\"Best parameters set:\")\n",
    "print(KNN_random_search.best_params_)\n",
    "print(KNN_random_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "[CV 1/3] END countvectorizer__max_df=1.0, countvectorizer__max_features=10860, countvectorizer__ngram_range=(1, 1), decisiontreeregressor__max_depth=30;, score=(train=0.547, test=0.258) total time=   5.2s\n",
      "[CV 2/3] END countvectorizer__max_df=1.0, countvectorizer__max_features=10860, countvectorizer__ngram_range=(1, 1), decisiontreeregressor__max_depth=30;, score=(train=0.556, test=0.251) total time=   5.4s\n",
      "[CV 3/3] END countvectorizer__max_df=1.0, countvectorizer__max_features=10860, countvectorizer__ngram_range=(1, 1), decisiontreeregressor__max_depth=30;, score=(train=0.557, test=0.261) total time=   5.5s\n",
      "[CV 1/3] END countvectorizer__max_df=0.5, countvectorizer__max_features=15734, countvectorizer__ngram_range=(1, 2), decisiontreeregressor__max_depth=30;, score=(train=0.545, test=0.262) total time=   8.7s\n",
      "[CV 2/3] END countvectorizer__max_df=0.5, countvectorizer__max_features=15734, countvectorizer__ngram_range=(1, 2), decisiontreeregressor__max_depth=30;, score=(train=0.552, test=0.250) total time=   8.8s\n",
      "[CV 3/3] END countvectorizer__max_df=0.5, countvectorizer__max_features=15734, countvectorizer__ngram_range=(1, 2), decisiontreeregressor__max_depth=30;, score=(train=0.553, test=0.262) total time=   8.7s\n",
      "[CV 1/3] END countvectorizer__max_df=1.0, countvectorizer__max_features=14426, countvectorizer__ngram_range=(1, 1), decisiontreeregressor__max_depth=40;, score=(train=0.660, test=0.244) total time=   7.8s\n",
      "[CV 2/3] END countvectorizer__max_df=1.0, countvectorizer__max_features=14426, countvectorizer__ngram_range=(1, 1), decisiontreeregressor__max_depth=40;, score=(train=0.670, test=0.237) total time=   8.0s\n",
      "[CV 3/3] END countvectorizer__max_df=1.0, countvectorizer__max_features=14426, countvectorizer__ngram_range=(1, 1), decisiontreeregressor__max_depth=40;, score=(train=0.674, test=0.241) total time=   7.9s\n",
      "[CV 1/3] END countvectorizer__max_df=1.0, countvectorizer__max_features=11685, countvectorizer__ngram_range=(1, 1), decisiontreeregressor__max_depth=25;, score=(train=0.480, test=0.260) total time=   4.2s\n",
      "[CV 2/3] END countvectorizer__max_df=1.0, countvectorizer__max_features=11685, countvectorizer__ngram_range=(1, 1), decisiontreeregressor__max_depth=25;, score=(train=0.486, test=0.256) total time=   4.3s\n",
      "[CV 3/3] END countvectorizer__max_df=1.0, countvectorizer__max_features=11685, countvectorizer__ngram_range=(1, 1), decisiontreeregressor__max_depth=25;, score=(train=0.486, test=0.259) total time=   4.3s\n",
      "[CV 1/3] END countvectorizer__max_df=0.75, countvectorizer__max_features=16949, countvectorizer__ngram_range=(1, 2), decisiontreeregressor__max_depth=35;, score=(train=0.605, test=0.256) total time=  10.0s\n",
      "[CV 2/3] END countvectorizer__max_df=0.75, countvectorizer__max_features=16949, countvectorizer__ngram_range=(1, 2), decisiontreeregressor__max_depth=35;, score=(train=0.613, test=0.247) total time=  10.4s\n",
      "[CV 3/3] END countvectorizer__max_df=0.75, countvectorizer__max_features=16949, countvectorizer__ngram_range=(1, 2), decisiontreeregressor__max_depth=35;, score=(train=0.615, test=0.250) total time=  10.5s\n",
      "[CV 1/3] END countvectorizer__max_df=0.5, countvectorizer__max_features=11184, countvectorizer__ngram_range=(1, 2), decisiontreeregressor__max_depth=25;, score=(train=0.478, test=0.258) total time=   7.0s\n",
      "[CV 2/3] END countvectorizer__max_df=0.5, countvectorizer__max_features=11184, countvectorizer__ngram_range=(1, 2), decisiontreeregressor__max_depth=25;, score=(train=0.482, test=0.258) total time=   7.2s\n",
      "[CV 3/3] END countvectorizer__max_df=0.5, countvectorizer__max_features=11184, countvectorizer__ngram_range=(1, 2), decisiontreeregressor__max_depth=25;, score=(train=0.483, test=0.264) total time=   7.2s\n",
      "[CV 1/3] END countvectorizer__max_df=0.75, countvectorizer__max_features=16396, countvectorizer__ngram_range=(1, 2), decisiontreeregressor__max_depth=20;, score=(train=0.404, test=0.263) total time=   6.2s\n",
      "[CV 2/3] END countvectorizer__max_df=0.75, countvectorizer__max_features=16396, countvectorizer__ngram_range=(1, 2), decisiontreeregressor__max_depth=20;, score=(train=0.406, test=0.263) total time=   6.1s\n",
      "[CV 3/3] END countvectorizer__max_df=0.75, countvectorizer__max_features=16396, countvectorizer__ngram_range=(1, 2), decisiontreeregressor__max_depth=20;, score=(train=0.407, test=0.263) total time=   6.0s\n",
      "[CV 1/3] END countvectorizer__max_df=0.5, countvectorizer__max_features=18666, countvectorizer__ngram_range=(1, 1), decisiontreeregressor__max_depth=25;, score=(train=0.480, test=0.259) total time=   4.3s\n",
      "[CV 2/3] END countvectorizer__max_df=0.5, countvectorizer__max_features=18666, countvectorizer__ngram_range=(1, 1), decisiontreeregressor__max_depth=25;, score=(train=0.486, test=0.259) total time=   4.5s\n",
      "[CV 3/3] END countvectorizer__max_df=0.5, countvectorizer__max_features=18666, countvectorizer__ngram_range=(1, 1), decisiontreeregressor__max_depth=25;, score=(train=0.486, test=0.259) total time=   4.4s\n",
      "[CV 1/3] END countvectorizer__max_df=1.0, countvectorizer__max_features=10189, countvectorizer__ngram_range=(1, 2), decisiontreeregressor__max_depth=30;, score=(train=0.545, test=0.258) total time=   8.2s\n",
      "[CV 2/3] END countvectorizer__max_df=1.0, countvectorizer__max_features=10189, countvectorizer__ngram_range=(1, 2), decisiontreeregressor__max_depth=30;, score=(train=0.552, test=0.246) total time=   8.1s\n",
      "[CV 3/3] END countvectorizer__max_df=1.0, countvectorizer__max_features=10189, countvectorizer__ngram_range=(1, 2), decisiontreeregressor__max_depth=30;, score=(train=0.555, test=0.259) total time=   8.3s\n",
      "[CV 1/3] END countvectorizer__max_df=1.0, countvectorizer__max_features=11267, countvectorizer__ngram_range=(1, 2), decisiontreeregressor__max_depth=20;, score=(train=0.404, test=0.263) total time=   5.6s\n",
      "[CV 2/3] END countvectorizer__max_df=1.0, countvectorizer__max_features=11267, countvectorizer__ngram_range=(1, 2), decisiontreeregressor__max_depth=20;, score=(train=0.405, test=0.260) total time=   5.4s\n",
      "[CV 3/3] END countvectorizer__max_df=1.0, countvectorizer__max_features=11267, countvectorizer__ngram_range=(1, 2), decisiontreeregressor__max_depth=20;, score=(train=0.407, test=0.261) total time=   5.7s\n",
      "Best parameters set:\n",
      "{'countvectorizer__max_df': 0.75, 'countvectorizer__max_features': 16396, 'countvectorizer__ngram_range': (1, 2), 'decisiontreeregressor__max_depth': 20}\n",
      "0.26310191844796543\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from scipy.stats import randint\n",
    "\n",
    "# Step 1: Create a pipeline with CountVectorizer and DecisionTreeRegressor\n",
    "decision_tree_model = make_pipeline(CountVectorizer(), DecisionTreeRegressor())\n",
    "\n",
    "# Step 2: Randomized search\n",
    "parameters = {\n",
    "    'countvectorizer__max_features': randint(10000, 20000),\n",
    "    'countvectorizer__max_df': (0.5, 0.75, 1.0),\n",
    "    'decisiontreeregressor__max_depth': [20,25,30,35,40],\n",
    "}\n",
    "\n",
    "decision_tree_random_search = RandomizedSearchCV(decision_tree_model, parameters, n_iter=10, cv=3, random_state=42,verbose=3,return_train_score=True)\n",
    "\n",
    "decision_tree_random_search.fit(X_train, y_train_intervals)\n",
    "\n",
    "# Output the best parameters\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print(decision_tree_random_search.best_params_)\n",
    "print(decision_tree_random_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepoceesing = make_column_transformer(\n",
    "    (make_pipeline(SimpleImputer(strategy='mean'), StandardScaler()), ['points']),\n",
    "    \n",
    "    (CountVectorizer(), 'tokens')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
      "[CV 1/3] END rf__max_depth=9, rf__min_samples_leaf=4, rf__min_samples_split=9, rf__n_estimators=288, tfidf__ngram_range=(1, 1);, score=(train=-6.527, test=-6.770) total time= 6.3min\n",
      "[CV 2/3] END rf__max_depth=5, rf__min_samples_leaf=8, rf__min_samples_split=6, rf__n_estimators=199, tfidf__ngram_range=(1, 2);, score=(train=-7.451, test=-7.788) total time= 6.3min\n",
      "[CV 3/3] END rf__max_depth=5, rf__min_samples_leaf=8, rf__min_samples_split=6, rf__n_estimators=199, tfidf__ngram_range=(1, 2);, score=(train=-7.467, test=-7.871) total time= 6.4min\n",
      "[CV 2/3] END rf__max_depth=9, rf__min_samples_leaf=10, rf__min_samples_split=4, rf__n_estimators=314, tfidf__ngram_range=(1, 1);, score=(train=-6.622, test=-6.815) total time= 6.4min\n",
      "[CV 1/3] END rf__max_depth=9, rf__min_samples_leaf=10, rf__min_samples_split=4, rf__n_estimators=314, tfidf__ngram_range=(1, 1);, score=(train=-6.569, test=-6.776) total time= 6.5min\n",
      "[CV 3/3] END rf__max_depth=9, rf__min_samples_leaf=10, rf__min_samples_split=4, rf__n_estimators=314, tfidf__ngram_range=(1, 1);, score=(train=-6.575, test=-6.773) total time= 6.5min\n",
      "[CV 2/3] END rf__max_depth=9, rf__min_samples_leaf=4, rf__min_samples_split=9, rf__n_estimators=288, tfidf__ngram_range=(1, 1);, score=(train=-6.581, test=-6.808) total time= 8.3min\n",
      "[CV 3/3] END rf__max_depth=9, rf__min_samples_leaf=4, rf__min_samples_split=9, rf__n_estimators=288, tfidf__ngram_range=(1, 1);, score=(train=-6.534, test=-6.760) total time= 8.9min\n",
      "[CV 1/3] END rf__max_depth=5, rf__min_samples_leaf=8, rf__min_samples_split=6, rf__n_estimators=199, tfidf__ngram_range=(1, 2);, score=(train=-7.454, test=-7.798) total time= 9.1min\n",
      "[CV 1/3] END rf__max_depth=5, rf__min_samples_leaf=6, rf__min_samples_split=6, rf__n_estimators=357, tfidf__ngram_range=(1, 2);, score=(train=-7.463, test=-7.807) total time=14.5min\n",
      "[CV 2/3] END rf__max_depth=5, rf__min_samples_leaf=6, rf__min_samples_split=6, rf__n_estimators=357, tfidf__ngram_range=(1, 2);, score=(train=-7.457, test=-7.789) total time=12.2min\n",
      "[CV 3/3] END rf__max_depth=5, rf__min_samples_leaf=6, rf__min_samples_split=6, rf__n_estimators=357, tfidf__ngram_range=(1, 2);, score=(train=-7.468, test=-7.868) total time=12.2min\n",
      "[CV 1/3] END rf__max_depth=6, rf__min_samples_leaf=6, rf__min_samples_split=3, rf__n_estimators=291, tfidf__ngram_range=(1, 2);, score=(train=-7.149, test=-7.584) total time=12.6min\n",
      "[CV 2/3] END rf__max_depth=6, rf__min_samples_leaf=6, rf__min_samples_split=3, rf__n_estimators=291, tfidf__ngram_range=(1, 2);, score=(train=-7.189, test=-7.592) total time=15.0min\n",
      "[CV 3/3] END rf__max_depth=6, rf__min_samples_leaf=6, rf__min_samples_split=3, rf__n_estimators=291, tfidf__ngram_range=(1, 2);, score=(train=-7.183, test=-7.631) total time=15.0min\n",
      "[CV 1/3] END rf__max_depth=7, rf__min_samples_leaf=1, rf__min_samples_split=7, rf__n_estimators=352, tfidf__ngram_range=(1, 2);, score=(train=-6.838, test=-7.357) total time=17.7min\n",
      "[CV 3/3] END rf__max_depth=7, rf__min_samples_leaf=1, rf__min_samples_split=7, rf__n_estimators=352, tfidf__ngram_range=(1, 2);, score=(train=-6.904, test=-7.415) total time=16.6min\n",
      "[CV 2/3] END rf__max_depth=7, rf__min_samples_leaf=1, rf__min_samples_split=7, rf__n_estimators=352, tfidf__ngram_range=(1, 2);, score=(train=-6.899, test=-7.381) total time=18.6min\n",
      "Best parameters: {'rf__max_depth': 9, 'rf__min_samples_leaf': 4, 'rf__min_samples_split': 9, 'rf__n_estimators': 288, 'tfidf__ngram_range': (1, 1)}\n",
      "Best score (MSE): 6.779349739456623\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "# Define the pipeline\n",
    "rf_pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('rf', RandomForestRegressor())\n",
    "])\n",
    "\n",
    "# Parameters for RandomizedSearchCV\n",
    "rf_param_dist = {\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2)],\n",
    "    'rf__n_estimators': randint(100, 500),\n",
    "    'rf__max_depth': randint(3, 10),\n",
    "    'rf__min_samples_split': randint(2, 11),\n",
    "    'rf__min_samples_leaf': randint(1, 11)\n",
    "}\n",
    "\n",
    "# Set up RandomizedSearchCV\n",
    "rf_random_search = RandomizedSearchCV(rf_pipeline, param_distributions=rf_param_dist, \n",
    "                                       n_iter=6, cv=3, scoring='neg_mean_squared_error', random_state=42, verbose=3, n_jobs=-1, return_train_score=True)\n",
    "\n",
    "# Fit the model\n",
    "rf_random_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and score\n",
    "print(\"Best parameters:\", rf_random_search.best_params_)\n",
    "print(\"Best score (MSE):\", -rf_random_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-6.87858949283535"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random_search.score(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "509",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
